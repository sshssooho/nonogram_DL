{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1638970486949
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\r\n",
        "    def __init__(self, in_channels, out_channels, dropout, row):\r\n",
        "        super.__init__(self)\r\n",
        "        \r\n",
        "        # if row is True, possibility maps from rows are given as input\r\n",
        "        if row is True:\r\n",
        "            kernel_size = (1,3)\r\n",
        "            padding = (0, 1)\r\n",
        "\r\n",
        "        else:\r\n",
        "            kernel_size = (3, 1)\r\n",
        "            padding = (1, 0)\r\n",
        "            \r\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=1, padding=padding, dilation=1)\r\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "        self.dropout = nn.Dropout2d(dropout)\r\n",
        "\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "\r\n",
        "        identity = x\r\n",
        "\r\n",
        "        x = self.conv(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.relu(x)\r\n",
        "\r\n",
        "        x = self.conv(x)\r\n",
        "        x = self.bn1(x)\r\n",
        "\r\n",
        "        x += identity\r\n",
        "\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.dropout(x)\r\n",
        "\r\n",
        "        return x\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super.__init__(self)\r\n",
        "\r\n",
        "        self.rclayer1 = ConvBlock(in_channels = 1, out_channels=32, dropout = 0.1, row = True)\r\n",
        "        self.rclayer2 = ConvBlock(in_channels = 32, out_channels = 64, dropout = 0.1, row = True)\r\n",
        "        self.rclayer3 = ConvBlock(in_channels = 64, out_channels = 128, dropout = 0.1, row = True)\r\n",
        "        self.rclayer4 = ConvBlock(in_channels = 128, out_channels = 256, dropout = 0.1, row = True)\r\n",
        "\r\n",
        "        self.cclayer1 = ConvBlock(inchannels = 1, out_channels= 32, dropout = 0.1, row = False)\r\n",
        "        self.cclayer2 = ConvBlock(inchannels = 32, out_channels= 64, dropout = 0.1, row = False)\r\n",
        "        self.cclayer3 = ConvBlock(inchannels = 64, out_channels= 128, dropout = 0.1, row = False)\r\n",
        "        self.cclayer4 = ConvBlock(inchannels = 128, out_channels= 256, dropout = 0.1, row = False)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        assert x.ndim == 4 # Shape (Batch, Channel = 2, Height, Width)\r\n",
        "\r\n",
        "        row_x = x[:,0,:,:]\r\n",
        "        column_x = x[:,1,:,:]\r\n",
        "\r\n",
        "        print(row_x)\r\n",
        "        print(column_x)\r\n",
        "\r\n",
        "        row_x = self.rclayer1(x)\r\n",
        "        row_x = self.rclayer2(x)\r\n",
        "        row_x = self.rclayer3(x)\r\n",
        "        row_x = self.rclayer4(x)\r\n",
        "\r\n",
        "        column_x = self.cclayer1(x)\r\n",
        "        column_x = self.cclayer2(x)\r\n",
        "        column_x = self.cclayer3(x)\r\n",
        "        column_x = self.cclayer4(x)\r\n",
        "\r\n",
        "        return row_x, column_x\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e7d97dec0fea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrclayer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PSPModule(nn.Module):\r\n",
        "    def __init__(self, features, out_features=1024, sizes=(1, 2, 3, 6)):\r\n",
        "        super().__init__()\r\n",
        "        self.stages = []\r\n",
        "        self.stages = nn.ModuleList([self._make_stage(features, size) for size in sizes])\r\n",
        "        self.bottleneck = nn.Conv2d(features * (len(sizes) + 1), out_features, kernel_size=1)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def _make_stage(self, features, size):\r\n",
        "        prior = nn.AdaptiveAvgPool2d(output_size=(size, size))\r\n",
        "        conv = nn.Conv2d(features, features, kernel_size=1, bias=False)\r\n",
        "        return nn.Sequential(prior, conv)\r\n",
        "\r\n",
        "    def forward(self, feats):\r\n",
        "        h, w = feats.size(2), feats.size(3)\r\n",
        "        priors = [F.upsample(input=stage(feats), size=(h, w), mode='bilinear') for stage in self.stages] + [feats]\r\n",
        "        bottle = self.bottleneck(torch.cat(priors, 1))\r\n",
        "        return self.relu(bottle)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PSPUpsample(nn.Module):\r\n",
        "    def __init__(self, in_channels, out_channels):\r\n",
        "        super().__init__()\r\n",
        "        self.conv = nn.Sequential(\r\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\r\n",
        "            nn.BatchNorm2d(out_channels),\r\n",
        "            nn.PReLU()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        h, w = 2 * x.size(2), 2 * x.size(3)\r\n",
        "        p = F.upsample(input=x, size=(h, w), mode='bilinear')\r\n",
        "        return self.conv(p)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PSPNet(nn.Module):\r\n",
        "    def __init__(self, n_classes=18, sizes=(1, 2, 3, 6), psp_size=2048, deep_features_size=1024, backend='resnet34',\r\n",
        "                 pretrained=True):\r\n",
        "        super().__init__()\r\n",
        "        self.feats = getattr(extractors, backend)(pretrained)\r\n",
        "        self.psp = PSPModule(psp_size, 1024, sizes)\r\n",
        "        self.drop_1 = nn.Dropout2d(p=0.3)\r\n",
        "\r\n",
        "        self.up_1 = PSPUpsample(1024, 256)\r\n",
        "        self.up_2 = PSPUpsample(256, 64)\r\n",
        "        self.up_3 = PSPUpsample(64, 64)\r\n",
        "\r\n",
        "        self.drop_2 = nn.Dropout2d(p=0.15)\r\n",
        "        self.final = nn.Sequential(\r\n",
        "            nn.Conv2d(64, n_classes, kernel_size=1),\r\n",
        "            nn.LogSoftmax()\r\n",
        "        )\r\n",
        "\r\n",
        "        self.classifier = nn.Sequential(\r\n",
        "            nn.Linear(deep_features_size, 256),\r\n",
        "            nn.ReLU(),\r\n",
        "            nn.Linear(256, n_classes)\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        f, class_f = self.feats(x) \r\n",
        "        p = self.psp(f)\r\n",
        "        p = self.drop_1(p)\r\n",
        "\r\n",
        "        p = self.up_1(p)\r\n",
        "        p = self.drop_2(p)\r\n",
        "\r\n",
        "        p = self.up_2(p)\r\n",
        "        p = self.drop_2(p)\r\n",
        "\r\n",
        "        p = self.up_3(p)\r\n",
        "        p = self.drop_2(p)\r\n",
        "\r\n",
        "        auxiliary = F.adaptive_max_pool2d(input=class_f, output_size=(1, 1)).view(-1, class_f.size(1))\r\n",
        "\r\n",
        "        return self.final(p), self.classifier(auxiliary)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}