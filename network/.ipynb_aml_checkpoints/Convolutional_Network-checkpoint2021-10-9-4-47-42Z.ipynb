{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1636431860484
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\r\n",
        "    def __init__(self, in_channels, out_channels, skip_connection = False, mid_channels = None):\r\n",
        "        super(DoubleConv, self).__init__()\r\n",
        "        self.skip_connection = skip_connection\r\n",
        "        if not mid_channels:\r\n",
        "            mid_channels = out_channels\r\n",
        "        self.double_conv = nn.Sequential(\r\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size = 3, padding = 1),\r\n",
        "            nn.BatchNorm2d(mid_channels),\r\n",
        "            nn.ReLU(inplace = True),\r\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size = 3, padding = 1),\r\n",
        "            nn.BatchNorm2d(out_channels)\r\n",
        "        )\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        if self.skip_connection == False:\r\n",
        "            x = self.double_conv(x)\r\n",
        "            x = self.relu(x)\r\n",
        "            return x\r\n",
        "        else:\r\n",
        "            # double_conv output is same shape\r\n",
        "            x = self.double_conv(x) + x\r\n",
        "            x = self.relu(x)\r\n",
        "            return x"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636432220651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OutConv(nn.Module):\r\n",
        "    def __init__(self, in_channels, out_channels):\r\n",
        "        super(OutConv, self).__init__()\r\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1)\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        return self.conv(x)\r\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636432221192
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNnet(nn.Module):\r\n",
        "    def __init__(self, n_channels):\r\n",
        "        super(RNnet, self).__init__()\r\n",
        "        self.n_channels = n_channels\r\n",
        "\r\n",
        "        self.layer1 = DoubleConv(n_channels, 64, skip_connection = False, mid_channels = None)\r\n",
        "        self.layer2 = self._make_layer(blocks = 4, in_channels = 64, out_channels = 64, skip_connection = True, mid_channels=None)\r\n",
        "        self.layer3 = DoubleConv(64, 128, skip_connection= False, mid_channels = None)\r\n",
        "        self.layer4 = self._make_layer(blocks = 4, in_channels = 128, out_channles = 128, skip_connection = True, mid_channels = None)\r\n",
        "        self.layer5 = OutConv(128, 1)\r\n",
        "        self.sigmoid = nn.Sigmoid()\r\n",
        "    \r\n",
        "    def _make_layer(self, blocks, in_channels, out_channels, skip_connection, mid_channels):\r\n",
        "        layers = []\r\n",
        "        for _ in range(1, blocks):\r\n",
        "            layers.append(DoubleConv(in_channels, out_channels, skip_connection=skip_connection, mid_channels=mid_channels))\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.layer5(x)\r\n",
        "        x = self.sigmoid(x)\r\n",
        "        return x"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1636432221929
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}