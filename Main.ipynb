{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from heapq import nlargest\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# !pip install torch-optimizer\n",
    "import torch_optimizer as optim   \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import MLP\n",
    "from MLP import MLP_Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('loading...', flush = True)\n",
    "X_train = np.load('./data/X_train.npy', allow_pickle= True)  # X_train and X_test is pickled\n",
    "Y_train = np.load('./data/Y_train.npy')\n",
    "X_test = np.load('./data/X_test.npy', allow_pickle= True)\n",
    "Y_test = np.load('./data/Y_test.npy')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - converting conditions into 'possibility maps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 2, 8), (60000, 8, 8), (10000, 2, 8), (10000, 8, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchcombinationsUtil(k, n):\n",
    "    \"\"\"\n",
    "    k: number of elements (>= 1)\n",
    "    n: total sum of elements\n",
    "    return all possible combinations of k numbers that add up to n, regarding its order\n",
    "    \"\"\"\n",
    "    # Recursive function\n",
    "    \n",
    "    if k == 1:\n",
    "        return [[n]]\n",
    "    else:\n",
    "        output = []\n",
    "        for i in range(0, n+1):\n",
    "            output += [[i]+items for items in searchcombinationsUtil(k-1, n-i)]\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_val_calculator(constraint, N):\n",
    "    \"\"\"\n",
    "    constraint: the condition(constraint) of a single row/column in a nonogram\n",
    "    N: the length of the width/height of the nonogram\n",
    "    returns a vector with length N, and each value of the vector is the possibility of the corresponding pixel to be colored\n",
    "    \"\"\"\n",
    "    total_colored = np.sum(constraint)\n",
    "\n",
    "    if(len(constraint) == 0):\n",
    "        return [0 for _ in range(N)]\n",
    "    else:\n",
    "        combinations = searchcombinationsUtil(k=int(len(constraint)+1), n= int(N-total_colored-len(constraint)+1))\n",
    "        output = []\n",
    "\n",
    "        for each_combination in combinations:\n",
    "            pixel_val = []\n",
    "            for idx, elements in enumerate(each_combination):\n",
    "                if (idx == 0) or (idx == len(constraint)):\n",
    "                    pixel_val += [0 for _ in range(elements)]\n",
    "                else:\n",
    "                    pixel_val += [0 for _ in range(elements+1)]\n",
    "                if idx != (len(constraint)):\n",
    "                    pixel_val += [1 for _ in range(constraint[idx])]\n",
    "            output.append(pixel_val)\n",
    "        \n",
    "        output = np.array(output, dtype = np.float64)\n",
    "        output = np.sum(output, axis = 0)\n",
    "        output/= len(combinations)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.33333333, 0.33333333, 0.66666667])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_val_calculator([7, 1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibility_map_generator(X):\n",
    "    \"\"\"\n",
    "    X: (batch_size, 2, N) or (batch_size, 2, N, t) only if all constraints are composed of same number of blocks (=t)\n",
    "    (2, N): each nonogram puzzle\n",
    "    2 stands for each condition (row condition, column condition)\n",
    "    N stands for the number of pixels (Number of total constraints)\n",
    "    returns possibility_map: (batch_size, 2, N, N)\n",
    "    \"\"\"\n",
    "    assert X.ndim in [3, 4]\n",
    "    \n",
    "    if X.ndim == 3:\n",
    "        N = X.shape[-1]\n",
    "    if X.ndim == 4:\n",
    "        N = X.shape[-2]\n",
    "\n",
    "    possibility_map = []\n",
    "    for puzzles in tqdm(X):\n",
    "        row_condition = puzzles[0]\n",
    "        row_map = []\n",
    "        for constraints in row_condition:\n",
    "            row_map.append(pixel_val_calculator(constraint=constraints, N=N))\n",
    "        row_map = np.array(row_map)\n",
    "\n",
    "        column_condition = puzzles[1]\n",
    "        column_map = []\n",
    "        for constraints in column_condition:\n",
    "            column_map.append(pixel_val_calculator(constraint=constraints, N=N))\n",
    "        column_map = np.array(column_map)\n",
    "        column_map = column_map.T\n",
    "\n",
    "        possibility_map.append(np.array([row_map, column_map]))\n",
    "        \n",
    "    possibility_map = np.asarray(possibility_map)\n",
    "    return possibility_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 964.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[1. , 1. ],\n",
       "         [0.5, 0.5]],\n",
       "\n",
       "        [[0.5, 1. ],\n",
       "         [0.5, 1. ]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[2], [1]], [[1], [2]]])\n",
    "print(a.shape)\n",
    "possibility_map_generator(np.expand_dims(a,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, X_mapped=None, y=None):\n",
    "\n",
    "        assert X.ndim in [3, 4]\n",
    "\n",
    "        if X.ndim == 3:\n",
    "            N = X.shape[-1]\n",
    "            self.X = np.array([[np.array([k + [0]*(N - len(k))for k in j]) for j in i] for i in X])\n",
    "        if X.ndim == 4:\n",
    "            N = X.shape[-2]\n",
    "\n",
    "\n",
    "        # pre-calculated possibility map if possible\n",
    "        if X_mapped is not None:\n",
    "            self.X_mapped = X_mapped\n",
    "        else:\n",
    "            self.X_mapped = possibility_map_generator(X)\n",
    "\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = np.array(self.X[idx])\n",
    "        mapped_inputs = np.array(self.X_mapped[idx], dtype = np.float64)\n",
    "        \n",
    "\n",
    "        if self.y is not None:    # Train\n",
    "            labels = self.y[idx]\n",
    "            labels = np.array(labels, dtype=np.float64)\n",
    "            return inputs, mapped_inputs, labels\n",
    "\n",
    "        else:                     # Test\n",
    "            return inputs, mapped_inputs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(batch_size, shuffle, num_workers, X, X_mapped=None, y=None):\n",
    "    dataset = NN_Dataset(X, X_mapped, y)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "                            num_workers=num_workers)\n",
    "\n",
    "    print(f'length : {len(dataset)}')\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, model, optimizer, train_loader, valid_loader, device):\n",
    "    start = time.time()\n",
    "\n",
    "    best_acc = 0\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        # Train\n",
    "        model.train()    \n",
    "        train_accuracies = []\n",
    "        train_losses = []\n",
    "        for i, (inputs, mapped_inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            mapped_inputs = torch.tensor(mapped_inputs, device=device, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, device=device, dtype=torch.float32)\n",
    "            labels = torch.flatten(labels, start_dim = 1)\n",
    "            \n",
    "            preds = model(mapped_inputs)\n",
    "\n",
    "            loss = MSELoss()\n",
    "            l = loss(preds, labels)\n",
    "            \n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            for idx, predictions in enumerate(preds):\n",
    "                total_colored = np.sum(np.array(inputs[idx][0]))\n",
    "                threshold = np.amin(nlargest(total_colored, predictions))\n",
    "                predictions = [1 if a >= threshold else 0 for a in predictions]\n",
    "                acc = accuracy_score(predictions, labels[idx])\n",
    "                train_accuracies.append(acc)\n",
    "            \n",
    "            \n",
    "            train_losses.append(l.item())\n",
    "        \n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_accuracies = []\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, mapped_inputs, labels in valid_loader:\n",
    "                \n",
    "                mapped_inputs = torch.tensor(mapped_inputs, device=device, dtype=torch.float32)\n",
    "                labels = torch.tensor(labels, device=device, dtype=torch.float32)\n",
    "                labels = torch.flatten(labels, start_dim = 1)\n",
    "\n",
    "                preds = model(mapped_inputs)\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "                for idx, predictions in enumerate(preds):\n",
    "                    total_colored = np.sum(np.array(inputs[idx][0]))\n",
    "                    threshold = np.amin(nlargest(total_colored, predictions))\n",
    "                    predictions = [1 if a >= threshold else 0 for a in predictions]\n",
    "                    acc = accuracy_score(predictions, labels[idx])\n",
    "                    val_accuracies.append(acc)\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "            \n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        train_acc = np.mean(train_accuracies)\n",
    "        val_acc = np.mean(val_accuracies)\n",
    "\n",
    "        if best_acc < valid_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_epoch = epoch\n",
    "            best_auc = valid_auc\n",
    "            print('saving model...', flush = True)\n",
    "            torch.save(model.state_dict(), './weights/MLP.pth')\n",
    "            print('done')\n",
    "\n",
    "        print(f'Epoch:{epoch}  Train Loss:{train_loss:.3f} | Valid Loss:{val_loss:.3f}')\n",
    "        print(f'Train  Acc:{train_acc:.3f}')\n",
    "        print(f'Valid  Acc:{valid_acc:.3f}')\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'\\nEpoch Process Time: {(end-start)/60:.2f}Minute')\n",
    "    print(f'Best Epoch:{best_epoch}, Best Acc:{best_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48000/48000 [03:09<00:00, 253.04it/s]\n",
      "100%|██████████| 10000/10000 [00:47<00:00, 211.23it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_mapped = possibility_map_generator(X_train)\n",
    "X_test_mapped = possibility_map_generator(X_test)\n",
    "\n",
    "X_train, X_val, X_train_mapped, X_val_mapped, Y_train, Y_val = train_test_split(X_train, X_train_mapped, Y_train, test_size = 0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38400, 2, 8) (9600, 2, 8) (38400, 2, 8, 8) (9600, 2, 8, 8) (38400, 8, 8) (9600, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_train_mapped.shape, X_val_mapped.shape, Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length : 38400\n",
      "length : 9600\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_loader(batch_size=32, shuffle=True, num_workers=0, X = X_train, X_mapped=X_train_mapped, y = Y_train) \n",
    "valid_loader = get_loader(batch_size=32, shuffle=False, num_workers=0, X = X_val, X_mapped = X_val_mapped, y = Y_val) \n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "num_pixels = X_train.shape[-2] if X_train.ndim is 4 else X_train.shape[-1]\n",
    "\n",
    "model = MLP_Network(num_pixels = num_pixels).to(device)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1200 [00:00<?, ?it/s]C:\\Users\\qw070\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "C:\\Users\\qw070\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n",
      "  0%|          | 2/1200 [00:00<01:02, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1200 [00:00<01:06, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1200 [00:00<01:09, 17.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1200 [00:00<01:03, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 17/1200 [00:00<01:00, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1200 [00:01<01:02, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25/1200 [00:01<01:05, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 29/1200 [00:01<01:03, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1200 [00:01<01:10, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 37/1200 [00:02<01:11, 16.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 41/1200 [00:02<01:06, 17.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 44/1200 [00:02<01:02, 18.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 47/1200 [00:02<01:03, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 53/1200 [00:02<00:56, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 56/1200 [00:03<00:54, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 62/1200 [00:03<00:58, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 65/1200 [00:03<00:56, 19.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 71/1200 [00:03<00:55, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 74/1200 [00:03<00:52, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 80/1200 [00:04<00:49, 22.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 83/1200 [00:04<00:48, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 89/1200 [00:04<00:49, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 92/1200 [00:04<00:51, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 95/1200 [00:04<00:54, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1200 [00:05<00:58, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 106/1200 [00:05<00:58, 18.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 108/1200 [00:05<01:01, 17.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 112/1200 [00:05<01:01, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 116/1200 [00:06<01:00, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 121/1200 [00:06<00:56, 19.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 124/1200 [00:06<00:51, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 127/1200 [00:06<00:53, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 133/1200 [00:06<00:53, 19.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 139/1200 [00:07<00:49, 21.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 142/1200 [00:07<00:51, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 148/1200 [00:07<00:48, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 151/1200 [00:07<00:52, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 154/1200 [00:07<00:53, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 157/1200 [00:08<00:50, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 163/1200 [00:08<00:49, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 166/1200 [00:08<00:50, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 169/1200 [00:08<00:47, 21.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 175/1200 [00:08<00:50, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 181/1200 [00:09<00:43, 23.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 187/1200 [00:09<00:40, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 193/1200 [00:09<00:40, 24.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 196/1200 [00:09<00:41, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 199/1200 [00:10<00:56, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 205/1200 [00:10<00:54, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 207/1200 [00:10<00:55, 17.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 212/1200 [00:10<00:50, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 215/1200 [00:10<00:48, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 218/1200 [00:10<00:50, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n",
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 221/1200 [00:11<02:05,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64]) torch.Size([32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 221/1200 [00:12<00:54, 17.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-432ca66233e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m best_epoch, best_auprc, best_auc = train(epochs = epochs, model = model, optimizer = optimizer, train_loader = train_loader, \\\n\u001b[1;32m----> 2\u001b[1;33m                                          valid_loader = valid_loader, device = device)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-90-e23c93e30c3d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, model, optimizer, train_loader, valid_loader, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adamw.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_epoch, best_auprc, best_auc = train(epochs = epochs, model = model, optimizer = optimizer, train_loader = train_loader, \\\n",
    "                                         valid_loader = valid_loader, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            \n",
    "            inputs = torch.unsqueeze(inputs, 1)\n",
    "            inputs = torch.tensor(inputs, device=device, dtype=torch.float32)\n",
    "            \n",
    "            preds = model(inputs)\n",
    "            preds = preds.view(preds.nelement())\n",
    "            pred_list += (list(preds.detach().cpu().numpy()))\n",
    "\n",
    "        pred_list = np.array(pred_list)\n",
    "        \n",
    "    return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(init_channel = 1)\n",
    "model.load_state_dict(torch.load('./non_cardiac_weights/CNN_single_model.pth'))\n",
    "model = model.cuda()   # if cuda is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_loader(batch_size=256, shuffle=False, num_workers=6, X = x_test, y = None) \n",
    "CNN_single_prediction = inference(model = model, test_loader = test_loader, device = device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "845270aa2c885a888b45db3c1bae60d031e62d06b801817adb1ea555314d8774"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
