{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from heapq import nlargest\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_optimizer as optim   \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import MSELoss"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1639754177919
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import import_ipynb\n",
        "from network.FullyConnected_Network import FCnet\n",
        "from network.Transformer_Network import ATnet\n",
        "from network.Convolutional_Network import RNnet"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "importing Jupyter notebook from /mnt/batch/tasks/shared/LS_root/mounts/clusters/rhs/code/Users/qw07020821/NN_DL/nonogram_DL/network/FullyConnected_Network.ipynb\nimporting Jupyter notebook from /mnt/batch/tasks/shared/LS_root/mounts/clusters/rhs/code/Users/qw07020821/NN_DL/nonogram_DL/network/Transformer_Network.ipynb\nimporting Jupyter notebook from /mnt/batch/tasks/shared/LS_root/mounts/clusters/rhs/code/Users/qw07020821/NN_DL/nonogram_DL/network/Convolutional_Network.ipynb\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1639754267130
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('loading...', flush = True)\n",
        "X_train = np.load('./data/X_train.npy', allow_pickle= True)  # X_train and X_test is pickled\n",
        "Y_train = np.load('./data/Y_train.npy')\n",
        "X_test = np.load('./data/X_test.npy', allow_pickle= True)\n",
        "Y_test = np.load('./data/Y_test.npy')\n",
        "print('done')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "loading...\ndone\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1639754315729
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing - converting conditions into 'possibility maps'"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "((600000, 2, 10), (600000, 10, 10), (50000, 2, 10), (50000, 10, 10))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1639754316227
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def searchcombinationsUtil(k, n):\n",
        "    \"\"\"\n",
        "    k: number of elements (>= 1)\n",
        "    n: total sum of elements\n",
        "    return all possible combinations of k numbers that add up to n, regarding its order\n",
        "    \"\"\"\n",
        "    # Recursive function\n",
        "    \n",
        "    if k == 1:\n",
        "        return [[n]]\n",
        "    else:\n",
        "        output = []\n",
        "        for i in range(0, n+1):\n",
        "            output += [[i]+items for items in searchcombinationsUtil(k-1, n-i)]\n",
        "        return output        "
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639754316654
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_val_calculator(constraint, N):\n",
        "    \"\"\"\n",
        "    constraint: the condition(constraint) of a single row/column in a nonogram\n",
        "    N: the length of the width/height of the nonogram\n",
        "    returns a vector with length N, and each value of the vector is the possibility of the corresponding pixel to be colored\n",
        "    \"\"\"\n",
        "    total_colored = np.sum(constraint)\n",
        "\n",
        "    if(len(constraint) == 0):\n",
        "        return [0 for _ in range(N)]\n",
        "    else:\n",
        "        combinations = searchcombinationsUtil(k=int(len(constraint)+1), n= int(N-total_colored-len(constraint)+1))\n",
        "        output = []\n",
        "\n",
        "        for each_combination in combinations:\n",
        "            pixel_val = []\n",
        "            for idx, elements in enumerate(each_combination):\n",
        "                if (idx == 0) or (idx == len(constraint)):\n",
        "                    pixel_val += [0 for _ in range(elements)]\n",
        "                else:\n",
        "                    pixel_val += [0 for _ in range(elements+1)]\n",
        "                if idx != (len(constraint)):\n",
        "                    pixel_val += [1 for _ in range(constraint[idx])]\n",
        "            output.append(pixel_val)\n",
        "        \n",
        "        output = np.array(output, dtype = np.float64)\n",
        "        output = np.sum(output, axis = 0)\n",
        "        output/= len(combinations)\n",
        "\n",
        "        return output"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639754317103
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_val_calculator([7, 1], 10)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "array([0.66666667, 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 0.33333333, 0.33333333, 0.66666667])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639754317618
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def possibility_map_generator(X):\n",
        "    \"\"\"\n",
        "    X: (batch_size, 2, N) or (batch_size, 2, N, t) only if all constraints are composed of same number of blocks (=t)\n",
        "    (2, N): each nonogram puzzle\n",
        "    2 stands for each condition (row condition, column condition)\n",
        "    N stands for the number of pixels (Number of total constraints)\n",
        "    returns possibility_map: (batch_size, 2, N, N)\n",
        "    \"\"\"\n",
        "    assert X.ndim in [3, 4]\n",
        "    \n",
        "    if X.ndim == 3:\n",
        "        N = X.shape[-1]\n",
        "    if X.ndim == 4:\n",
        "        N = X.shape[-2]\n",
        "\n",
        "    possibility_map = []\n",
        "    for puzzles in tqdm(X):\n",
        "        row_condition = puzzles[0]\n",
        "        row_map = []\n",
        "        for constraints in row_condition:\n",
        "            row_map.append(pixel_val_calculator(constraint=constraints, N=N))\n",
        "        row_map = np.array(row_map)\n",
        "\n",
        "        column_condition = puzzles[1]\n",
        "        column_map = []\n",
        "        for constraints in column_condition:\n",
        "            column_map.append(pixel_val_calculator(constraint=constraints, N=N))\n",
        "        column_map = np.array(column_map)\n",
        "        column_map = column_map.T\n",
        "\n",
        "        possibility_map.append(np.array([row_map, column_map]))\n",
        "        \n",
        "    possibility_map = np.asarray(possibility_map)\n",
        "    return possibility_map"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1639754318179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[[2], [1]], [[1], [2]]])\n",
        "print(a.shape)\n",
        "possibility_map_generator(np.expand_dims(a,0))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r  0%|          | 0/1 [00:00<?, ?it/s]\r100%|██████████| 1/1 [00:00<00:00, 3452.10it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(2, 2, 1)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "array([[[[1. , 1. ],\n         [0.5, 0.5]],\n\n        [[0.5, 1. ],\n         [0.5, 1. ]]]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1639754318553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "class NN_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, X_mapped=None, y=None):\n",
        "\n",
        "        assert X.ndim in [3, 4]\n",
        "\n",
        "        if X.ndim == 3:\n",
        "            N = X.shape[-1]\n",
        "            self.X = np.array([[np.array([k + [0]*(N - len(k))for k in j]) for j in i] for i in X])\n",
        "        if X.ndim == 4:\n",
        "            N = X.shape[-2]\n",
        "\n",
        "\n",
        "        # pre-calculated possibility map if possible\n",
        "        if X_mapped is not None:\n",
        "            self.X_mapped = X_mapped\n",
        "        else:\n",
        "            self.X_mapped = possibility_map_generator(X)\n",
        "\n",
        "        self.y = y\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        inputs = np.array(self.X[idx])\n",
        "        mapped_inputs = np.array(self.X_mapped[idx], dtype = np.float64)\n",
        "        \n",
        "\n",
        "        if self.y is not None:    # Train\n",
        "            labels = self.y[idx]\n",
        "            labels = np.array(labels, dtype=np.float64)\n",
        "            return inputs, mapped_inputs, labels\n",
        "\n",
        "        else:                     # Test\n",
        "            return inputs, mapped_inputs\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1639754318928
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(batch_size, shuffle, num_workers, X, X_mapped=None, y=None):\n",
        "    dataset = NN_Dataset(X, X_mapped, y)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,\n",
        "                            num_workers=num_workers)\n",
        "\n",
        "    print(f'length : {len(dataset)}')\n",
        "    return data_loader"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1639754319343
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "print(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "cuda\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1639754319829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, model, optimizer, train_loader, valid_loader, device):\n",
        "    start = time.time()\n",
        "\n",
        "    best_acc = 0\n",
        "    for epoch in range(1, epochs+1):\n",
        "\n",
        "        # Train\n",
        "        model.train()    \n",
        "        train_accuracies = []\n",
        "        train_losses = []\n",
        "        for i, (inputs, mapped_inputs, labels) in enumerate(tqdm(train_loader)):\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            mapped_inputs = torch.tensor(mapped_inputs, device=device, dtype=torch.float32)\n",
        "            labels = torch.tensor(labels, device=device, dtype=torch.float32)\n",
        "            \n",
        "            preds = model(mapped_inputs)\n",
        "\n",
        "            loss = MSELoss()\n",
        "            l = loss(preds, labels)\n",
        "            \n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.flatten(preds, start_dim = 1).detach().cpu().numpy()\n",
        "            labels = torch.flatten(labels, start_dim = 1).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "            for idx, predictions in enumerate(preds):\n",
        "                total_colored = np.sum(np.array(inputs[idx][0]))\n",
        "                threshold = np.amin(nlargest(total_colored, predictions))\n",
        "                predictions = [1 if a >= threshold else 0 for a in predictions]\n",
        "                acc = accuracy_score(predictions, labels[idx])\n",
        "                train_accuracies.append(acc)\n",
        "            \n",
        "            \n",
        "            train_losses.append(l.item())\n",
        "        \n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_accuracies = []\n",
        "        val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, mapped_inputs, labels in valid_loader:\n",
        "                \n",
        "                mapped_inputs = torch.tensor(mapped_inputs, device=device, dtype=torch.float32)\n",
        "                labels = torch.tensor(labels, device=device, dtype=torch.float32)\n",
        "\n",
        "                \n",
        "                preds = model(mapped_inputs)\n",
        "\n",
        "\n",
        "                loss = MSELoss()\n",
        "                l = loss(preds, labels)\n",
        "                \n",
        "                val_losses.append(l.item())\n",
        "\n",
        "                preds = torch.flatten(preds, start_dim = 1).detach().cpu().numpy()\n",
        "                labels = torch.flatten(labels, start_dim = 1).detach().cpu().numpy()\n",
        "\n",
        "\n",
        "                for idx, predictions in enumerate(preds):\n",
        "                    total_colored = np.sum(np.array(inputs[idx][0]))\n",
        "                    threshold = np.amin(nlargest(total_colored, predictions))\n",
        "                    predictions = [1 if a >= threshold else 0 for a in predictions]\n",
        "                    acc = accuracy_score(predictions, labels[idx])\n",
        "                    val_accuracies.append(acc)\n",
        "            \n",
        "            val_losses.append(l.item())\n",
        "\n",
        "            \n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "        train_acc = np.mean(train_accuracies)\n",
        "        val_acc = np.mean(val_accuracies)\n",
        "\n",
        "        if best_acc < val_acc:\n",
        "            best_acc = val_acc\n",
        "            best_epoch = epoch\n",
        "            print('saving model...', flush = True)\n",
        "            if isinstance(model, ATnet):\n",
        "                torch.save(model.state_dict(), './weights/ATnet.pth')\n",
        "            if isinstance(model, FCnet):\n",
        "                torch.save(model.state_dict(), './weights/FCnet.pth')\n",
        "            if isinstance(model, RNnet):\n",
        "                torch.save(model.state_dict(), './weights/RNnet.pth')\n",
        "            print('done')\n",
        "\n",
        "        print(f'Epoch:{epoch}  Train Loss:{train_loss:.3f} | Valid Loss:{val_loss:.3f}')\n",
        "        print(f'Train  Acc:{train_acc:.3f}')\n",
        "        print(f'Valid  Acc:{val_acc:.3f}')\n",
        "\n",
        "    end = time.time()\n",
        "    print(f'\\nEpoch Process Time: {(end-start)/60:.2f}Minute')\n",
        "    print(f'Best Epoch:{best_epoch}, Best Acc:{best_acc:.3f}')"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1639543067110
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mapped = possibility_map_generator(X_train)\r\n",
        "X_test_mapped = possibility_map_generator(X_test)\r\n",
        "\r\n",
        "X_train, X_val, X_train_mapped, X_val_mapped, Y_train, Y_val = train_test_split(X_train, X_train_mapped, Y_train, test_size = 0.1, random_state = 42) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 50000/50000 [03:04<00:00, 270.97it/s]\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639754504775
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_val.shape, X_train_mapped.shape, X_val_mapped.shape, Y_train.shape, Y_val.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(540000, 2, 10) (60000, 2, 10) (540000, 2, 10, 10) (60000, 2, 10, 10) (540000, 10, 10) (60000, 10, 10)\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1639546774107
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = get_loader(batch_size=128, shuffle=True, num_workers=6, X = X_train, X_mapped=X_train_mapped, y = Y_train) \n",
        "valid_loader = get_loader(batch_size=128, shuffle=False, num_workers=6, X = X_val, X_mapped = X_val_mapped, y = Y_val) \n",
        "epochs = 50\n",
        "lr = 0.0005\n",
        "\n",
        "num_pixels = X_train.shape[-2] if X_train.ndim is 4 else X_train.shape[-1]\n",
        "\n",
        "# model = RNnet(n_channels = 2).to(device)\n",
        "\n",
        "ATnet_Config = {\n",
        "    'N': 10,\n",
        "    'emb_dim': 64,\n",
        "    'depth': 8, \n",
        "    'd_model': 64, \n",
        "    'num_heads': 8, \n",
        "    'expansion': 4, \n",
        "    'dropout': 0.1\n",
        "}\n",
        "\n",
        "model = ATnet(**ATnet_Config).to(device)\n",
        "#model = FCnet(num_pixels=10, model_depth=6).to(device)\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "length : 540000\nlength : 60000\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1639549957434
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "FCnet(\n  (block1): Linear_block(\n    (block): Sequential(\n      (0): Linear(in_features=200, out_features=400, bias=True)\n      (1): SELU()\n      (2): Dropout(p=0.2, inplace=False)\n    )\n  )\n  (block2): Sequential(\n    (0): Linear_block(\n      (block): Sequential(\n        (0): Linear(in_features=400, out_features=400, bias=True)\n        (1): SELU()\n        (2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (1): Linear_block(\n      (block): Sequential(\n        (0): Linear(in_features=400, out_features=400, bias=True)\n        (1): SELU()\n        (2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (2): Linear_block(\n      (block): Sequential(\n        (0): Linear(in_features=400, out_features=400, bias=True)\n        (1): SELU()\n        (2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (3): Linear_block(\n      (block): Sequential(\n        (0): Linear(in_features=400, out_features=400, bias=True)\n        (1): SELU()\n        (2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (4): Linear_block(\n      (block): Sequential(\n        (0): Linear(in_features=400, out_features=400, bias=True)\n        (1): SELU()\n        (2): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (5): Linear_block(\n      (block): Sequential(\n        (0): Linear(in_features=400, out_features=400, bias=True)\n        (1): SELU()\n        (2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (block3): Linear_block(\n    (block): Sequential(\n      (0): Linear(in_features=400, out_features=200, bias=True)\n      (1): SELU()\n      (2): Dropout(p=0.2, inplace=False)\n    )\n  )\n  (last_block): Sequential(\n    (0): Linear(in_features=200, out_features=100, bias=True)\n    (1): Sigmoid()\n  )\n)\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639549957775
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch, best_auprc, best_auc = train(epochs = epochs, model = model, optimizer = optimizer, train_loader = train_loader, \\\n",
        "                                         valid_loader = valid_loader, device = device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "  0%|          | 0/4219 [00:00<?, ?it/s]/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  from ipykernel import kernelapp as app\n100%|██████████| 4219/4219 [03:35<00:00, 19.57it/s]\n/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n100%|██████████| 4219/4219 [03:33<00:00, 19.72it/s]\n100%|██████████| 4219/4219 [03:30<00:00, 20.00it/s]\n100%|██████████| 4219/4219 [03:31<00:00, 19.91it/s]\n100%|██████████| 4219/4219 [03:31<00:00, 19.97it/s]\n100%|██████████| 4219/4219 [03:32<00:00, 19.83it/s]\n100%|██████████| 4219/4219 [03:34<00:00, 19.68it/s]\n100%|██████████| 4219/4219 [03:38<00:00, 19.35it/s]\n100%|██████████| 4219/4219 [03:33<00:00, 19.75it/s]\n100%|██████████| 4219/4219 [03:35<00:00, 19.55it/s]\n100%|██████████| 4219/4219 [03:34<00:00, 19.64it/s]\n100%|██████████| 4219/4219 [03:34<00:00, 19.67it/s]\n 88%|████████▊ | 3731/4219 [03:10<00:24, 19.62it/s]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "saving model...\ndone\nEpoch:1  Train Loss:0.190 | Valid Loss:0.190\nTrain  Acc:0.636\nValid  Acc:0.627\nsaving model...\ndone\nEpoch:2  Train Loss:0.191 | Valid Loss:0.190\nTrain  Acc:0.627\nValid  Acc:0.627\nEpoch:3  Train Loss:0.563 | Valid Loss:0.575\nTrain  Acc:0.428\nValid  Acc:0.425\nEpoch:4  Train Loss:0.565 | Valid Loss:0.560\nTrain  Acc:0.435\nValid  Acc:0.440\nEpoch:5  Train Loss:0.517 | Valid Loss:0.485\nTrain  Acc:0.483\nValid  Acc:0.515\nEpoch:6  Train Loss:0.451 | Valid Loss:0.435\nTrain  Acc:0.549\nValid  Acc:0.565\nEpoch:7  Train Loss:0.423 | Valid Loss:0.415\nTrain  Acc:0.577\nValid  Acc:0.585\nEpoch:8  Train Loss:0.413 | Valid Loss:0.410\nTrain  Acc:0.587\nValid  Acc:0.590\nEpoch:9  Train Loss:0.411 | Valid Loss:0.410\nTrain  Acc:0.587\nValid  Acc:0.590\nEpoch:10  Train Loss:0.415 | Valid Loss:0.420\nTrain  Acc:0.585\nValid  Acc:0.580\nEpoch:11  Train Loss:0.421 | Valid Loss:0.410\nTrain  Acc:0.579\nValid  Acc:0.590\nEpoch:12  Train Loss:0.405 | Valid Loss:0.410\nTrain  Acc:0.578\nValid  Acc:0.590\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-432ca66233e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m best_epoch, best_auprc, best_auc = train(epochs = epochs, model = model, optimizer = optimizer, train_loader = train_loader, \\\n\u001b[0;32m----> 2\u001b[0;31m                                          valid_loader = valid_loader, device = device)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-92b9f69033af>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, optimizer, train_loader, valid_loader, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mtotal_colored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_colored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-92b9f69033af>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mtotal_colored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_colored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, test_loader, device):\n",
        "    pred_list = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, mapped_inputs in test_loader:\n",
        "            \n",
        "            mapped_inputs = torch.tensor(mapped_inputs, device=device, dtype=torch.float32)\n",
        "            \n",
        "            N = mapped_inputs.shape[-1]\n",
        "            preds = model(mapped_inputs)\n",
        "            preds = torch.flatten(preds, start_dim = 1).detach().cpu().numpy()\n",
        "            \n",
        "            for idx, predictions in enumerate(preds):\n",
        "                total_colored = np.sum(np.array(inputs[idx][0]))\n",
        "                threshold = np.amin(nlargest(total_colored, predictions))\n",
        "                predictions = [1 if a >= threshold else 0 for a in predictions]\n",
        "                pred_list.append(np.array(predictions).reshape(N, N))\n",
        "\n",
        "        pred_list = np.array(pred_list)\n",
        "        \n",
        "    return pred_list"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1639754506526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_pixels = X_test.shape[-2] if X_test.ndim is 4 else X_test.shape[-1]\n",
        "\n",
        "\n",
        "ATnet_Config = {\n",
        "    'N': 10,\n",
        "    'emb_dim': 64,\n",
        "    'depth': 8, \n",
        "    'd_model': 64, \n",
        "    'num_heads': 8, \n",
        "    'expansion': 4, \n",
        "    'dropout': 0.1\n",
        "}\n",
        "model = ATnet(**ATnet_Config)\n",
        "model.load_state_dict(torch.load('./weights/ATnet.pth'))\n",
        "model.to(device)\n",
        "\n",
        "test_loader = get_loader(batch_size=256, shuffle=False, num_workers=6, X = X_test, X_mapped = X_test_mapped, y = None) \n",
        "\n",
        "pred_list = inference(model = model, test_loader = test_loader, device = device)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "length : 50000\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1639754636287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.load('./data/X_test.npy', allow_pickle=True)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639755327553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1480\r\n",
        "\r\n",
        "condition = X_test[i]\r\n",
        "print('row condition: ', end = \"\\n\")\r\n",
        "#print(*list(condition[0]))\r\n",
        "print(*list(condition[0]), sep = '\\n')\r\n",
        "print('column condition: ', end = \"\\n\")\r\n",
        "#print(*list(condition[1]))\r\n",
        "print(*list(condition[1]), sep = '\\n')\r\n",
        "\r\n",
        "print(np.round(X_test_mapped[i], 2))\r\n",
        "print(pred_list[i])\r\n",
        "print(Y_test[i])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "row condition: \n[2, 3]\n[1]\n[2, 1]\n[1, 1]\n[]\n[1]\n[1, 1]\n[2, 1]\n[1, 1]\n[1, 1]\ncolumn condition: \n[1]\n[1]\n[2]\n[]\n[2, 1, 2]\n[1, 1, 3, 1]\n[1, 2]\n[2]\n[1]\n[]\n[[[0.33 0.6  0.47 0.4  0.4  0.47 0.6  0.8  0.6  0.33]\n  [0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 ]\n  [0.25 0.46 0.39 0.36 0.32 0.29 0.25 0.21 0.21 0.25]\n  [0.22 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.22]\n  [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n  [0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 ]\n  [0.22 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.22]\n  [0.25 0.46 0.39 0.36 0.32 0.29 0.25 0.21 0.21 0.25]\n  [0.22 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.22]\n  [0.22 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.19 0.22]]\n\n [[0.1  0.1  0.11 0.   0.5  0.8  0.25 0.11 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.8  0.2  0.21 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.45 0.6  0.21 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.4  0.4  0.25 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.35 0.4  0.29 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.35 1.   0.32 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.4  1.   0.36 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.45 0.6  0.39 0.22 0.1  0.  ]\n  [0.1  0.1  0.22 0.   0.8  0.2  0.46 0.22 0.1  0.  ]\n  [0.1  0.1  0.11 0.   0.5  0.8  0.25 0.11 0.1  0.  ]]]\n[[1 1 0 0 1 1 1 0 0 0]\n [0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 1 1 0 1 0]\n [0 0 0 0 1 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 1 0 1 0 0]\n [0 0 0 0 1 1 0 1 0 0]\n [0 0 1 0 1 0 0 0 0 0]\n [0 0 1 0 0 1 0 0 0 0]]\n[[1 1 0 0 1 1 1 0 0 0]\n [0 0 0 0 1 0 0 0 0 0]\n [0 0 0 0 0 1 1 0 1 0]\n [0 0 0 0 1 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 1 0 1 0 0]\n [0 0 0 0 1 1 0 1 0 0]\n [0 0 1 0 1 0 0 0 0 0]\n [0 0 1 0 0 1 0 0 0 0]]\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639755679181
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./results/pred_ATnet.npy', pred_list)\r\n",
        "np.save('./results/label.npy', Y_test)"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639755782027
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list_flattened = pred_list.reshape(len(X_test), -1)\r\n",
        "label_list_flattened = Y_test.reshape(len(X_test), -1)\r\n",
        "\r\n",
        "test_accuracies = []\r\n",
        "\r\n",
        "if X_test.ndim == 3:\r\n",
        "    N = X_test.shape[-1]\r\n",
        "    X_test = np.array([[np.array([k + [0]*(N - len(k))for k in j]) for j in i] for i in X_test])\r\n",
        "if X_test.ndim == 4:\r\n",
        "    N = X_test.shape[-2]\r\n",
        "\r\n",
        "for idx, predictions in enumerate(pred_list_flattened):  \r\n",
        "    total_colored = np.sum(np.array(X_test[idx][0]))\r\n",
        "    threshold = np.amin(nlargest(total_colored, predictions))\r\n",
        "    predictions = [1 if a >= threshold else 0 for a in predictions]\r\n",
        "    acc = accuracy_score(predictions, label_list_flattened[idx])\r\n",
        "    test_accuracies.append(acc)\r\n",
        "\r\n",
        "print(np.mean(test_accuracies))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.8317584\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639754680704
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct_idx = [i for i in range(len(test_accuracies)) if test_accuracies[i] == 1.0]\r\n",
        "print(correct_idx)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[1480, 6546, 14808, 15657, 15841, 17159, 22091, 26231, 31241, 36101, 37176, 40695, 41756, 42536, 43598, 44140, 44476, 44604, 44621, 47706]\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639755670981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 259\r\n",
        "\r\n",
        "print(pred_list[i])\r\n",
        "print(Y_test[i])\r\n",
        "print(test_accuracies[i])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[[0 0 0 0 0 1 1 0 0 0]\n [1 0 1 1 1 0 0 0 0 1]\n [0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0]\n [0 1 0 1 0 0 0 0 1 0]\n [1 1 1 1 0 1 1 0 0 0]\n [0 0 0 0 0 1 1 0 0 0]\n [0 0 0 1 0 1 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0]]\n[[0 1 0 0 0 1 1 0 0 0]\n [1 0 1 0 1 0 0 0 1 0]\n [0 0 0 0 0 0 0 1 0 1]\n [1 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0]\n [0 1 0 1 0 0 0 0 1 0]\n [0 1 1 0 0 1 0 0 0 0]\n [0 0 0 0 0 1 1 0 0 0]\n [0 0 0 1 0 0 1 0 0 0]\n [0 0 0 1 0 0 0 0 0 0]]\n0.88\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639754692589
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_little = np.load('./data/X_test_little.npy', allow_pickle=True)\r\n",
        "Y_test_little = np.load('./data/Y_test_little.npy')\r\n",
        "\r\n",
        "X_test_little_mapped = possibility_map_generator(X_test_little)\r\n",
        "\r\n",
        "test_loader_little = get_loader(batch_size=256, shuffle=False, num_workers=6, X = X_test_little, X_mapped = X_test_little_mapped, y = None) \r\n",
        "\r\n",
        "pred_list_little = inference(model = model, test_loader = test_loader_little, device = device)\r\n",
        "\r\n",
        "\r\n",
        "pred_list_little_flattened = pred_list_little.reshape(len(X_test_little), -1)\r\n",
        "label_list_little_flattened = Y_test_little.reshape(len(X_test_little), -1)\r\n",
        "\r\n",
        "test_accuracies_little = []\r\n",
        "\r\n",
        "if X_test_little.ndim == 3:\r\n",
        "    N = X_test_little.shape[-1]\r\n",
        "    X_test_little = np.array([[np.array([k + [0]*(N - len(k))for k in j]) for j in i] for i in X_test_little])\r\n",
        "if X_test.ndim == 4:\r\n",
        "    N = X_test_little.shape[-2]\r\n",
        "\r\n",
        "for idx, predictions in enumerate(pred_list_little_flattened):  \r\n",
        "    total_colored = np.sum(np.array(X_test_little[idx][0]))\r\n",
        "    threshold = np.amin(nlargest(total_colored, predictions))\r\n",
        "    predictions = [1 if a >= threshold else 0 for a in predictions]\r\n",
        "    acc = accuracy_score(predictions, label_list_little_flattened[idx])\r\n",
        "    test_accuracies_little.append(acc)\r\n",
        "\r\n",
        "print(np.mean(test_accuracies_little))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 40000/40000 [00:43<00:00, 912.56it/s] \n/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "length : 40000\n0.9416190000000001\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639756159877
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./results/pred_ATnet_little.npy', pred_list_little)\r\n",
        "np.save('./results/label_little.npy', Y_test_little)"
      ],
      "outputs": [],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639757513531
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_many = np.load('./data/X_test_many.npy', allow_pickle=True)\r\n",
        "Y_test_many = np.load('./data/Y_test_many.npy')\r\n",
        "\r\n",
        "X_test_many_mapped = possibility_map_generator(X_test_many)\r\n",
        "\r\n",
        "test_loader_many = get_loader(batch_size=256, shuffle=False, num_workers=6, X = X_test_many, X_mapped = X_test_many_mapped, y = None) \r\n",
        "\r\n",
        "pred_list_many = inference(model = model, test_loader = test_loader_many, device = device)\r\n",
        "\r\n",
        "\r\n",
        "pred_list_many_flattened = pred_list_many.reshape(len(X_test_many), -1)\r\n",
        "label_list_many_flattened = Y_test_many.reshape(len(X_test_many), -1)\r\n",
        "\r\n",
        "test_accuracies_little = []\r\n",
        "\r\n",
        "if X_test_many.ndim == 3:\r\n",
        "    N = X_test_many.shape[-1]\r\n",
        "    X_test_many = np.array([[np.array([k + [0]*(N - len(k))for k in j]) for j in i] for i in X_test_many])\r\n",
        "if X_test.ndim == 4:\r\n",
        "    N = X_test_many.shape[-2]\r\n",
        "\r\n",
        "for idx, predictions in enumerate(pred_list_many_flattened):  \r\n",
        "    total_colored = np.sum(np.array(X_test_many[idx][0]))\r\n",
        "    threshold = np.amin(nlargest(total_colored, predictions))\r\n",
        "    predictions = [1 if a >= threshold else 0 for a in predictions]\r\n",
        "    acc = accuracy_score(predictions, label_list_many_flattened[idx])\r\n",
        "    test_accuracies_little.append(acc)\r\n",
        "\r\n",
        "print(np.mean(test_accuracies_little))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 40000/40000 [01:20<00:00, 496.99it/s]\n/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "length : 40000\n0.992267\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639756633508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_many = np.load('./data/X_test_many.npy', allow_pickle=True)\r\n",
        "\r\n",
        "i = 101\r\n",
        "\r\n",
        "condition = X_test_many[i]\r\n",
        "print('row condition: ', end = \"\\n\")\r\n",
        "#print(*list(condition[0]))\r\n",
        "print(*list(condition[0]), sep = '\\n')\r\n",
        "print('column condition: ', end = \"\\n\")\r\n",
        "#print(*list(condition[1]))\r\n",
        "print(*list(condition[1]), sep = '\\n')\r\n",
        "\r\n",
        "print(np.round(X_test_many_mapped[i], 2))\r\n",
        "\r\n",
        "print(pred_list_many[i])\r\n",
        "print(Y_test_many[i])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "row condition: \n[1, 2, 1]\n[1, 5, 1]\n[1, 2, 2]\n[4, 1, 1]\n[1, 3, 4]\n[1, 3, 1, 1]\n[1, 6, 1]\n[1, 1, 1, 1]\n[2, 1, 1, 1]\n[2, 4, 1]\ncolumn condition: \n[8]\n[2, 1, 2]\n[2, 1]\n[2, 6]\n[3, 3, 1]\n[3, 2, 2]\n[2, 1, 2, 1]\n[1, 3, 1]\n[1, 1, 1]\n[7, 1]\n[[[0.43 0.29 0.31 0.46 0.51 0.51 0.46 0.31 0.29 0.43]\n  [0.75 0.25 0.5  1.   1.   1.   1.   0.5  0.25 0.75]\n  [0.5  0.3  0.35 0.55 0.6  0.55 0.4  0.45 0.8  0.5 ]\n  [0.6  0.9  1.   1.   0.4  0.4  0.4  0.4  0.3  0.6 ]\n  [1.   0.   1.   1.   1.   0.   1.   1.   1.   1.  ]\n  [0.8  0.2  0.6  1.   1.   0.4  0.4  0.6  0.2  0.8 ]\n  [1.   0.   1.   1.   1.   1.   1.   1.   0.   1.  ]\n  [0.57 0.29 0.4  0.37 0.37 0.37 0.37 0.4  0.29 0.57]\n  [0.67 0.93 0.33 0.47 0.4  0.4  0.4  0.47 0.27 0.67]\n  [0.75 1.   0.25 0.5  1.   1.   1.   0.5  0.25 0.75]]\n\n [[0.33 0.5  0.25 0.67 0.75 0.75 0.8  0.5  0.38 0.67]\n  [0.67 0.8  0.46 1.   1.   1.   1.   0.3  0.27 1.  ]\n  [1.   0.45 0.39 0.33 1.   1.   0.2  0.35 0.29 1.  ]\n  [1.   0.4  0.36 0.33 0.25 0.25 0.6  0.55 0.29 1.  ]\n  [1.   0.35 0.32 1.   0.5  0.5  0.4  0.8  0.29 1.  ]\n  [1.   0.35 0.29 1.   1.   1.   0.4  0.8  0.29 1.  ]\n  [1.   0.4  0.25 1.   1.   0.5  1.   0.55 0.29 1.  ]\n  [1.   0.45 0.21 1.   0.5  0.25 0.6  0.35 0.29 0.33]\n  [0.67 0.8  0.21 1.   0.25 1.   0.2  0.3  0.27 0.33]\n  [0.33 0.5  0.25 0.67 0.75 0.75 0.8  0.5  0.38 0.67]]]\n[[0 1 0 1 1 0 0 0 0 0]\n [0 1 0 1 1 1 1 1 0 1]\n [1 0 0 0 1 1 1 0 1 1]\n [1 1 1 1 0 1 0 0 0 1]\n [1 0 1 1 1 0 1 1 1 1]\n [1 0 0 1 1 1 0 1 0 1]\n [1 0 1 1 1 1 1 1 0 1]\n [1 0 0 1 0 0 1 0 1 1]\n [1 1 0 1 0 1 0 1 0 0]\n [1 1 0 0 1 1 1 0 0 1]]\n[[0 1 0 1 1 0 1 0 0 0]\n [0 1 0 1 1 1 1 1 0 1]\n [1 0 0 0 1 1 0 0 1 1]\n [1 1 1 1 0 1 0 0 0 1]\n [1 0 1 1 1 0 1 1 1 1]\n [1 0 0 1 1 1 0 1 0 1]\n [1 0 1 1 1 1 1 1 0 1]\n [1 0 0 1 0 0 1 0 0 1]\n [1 1 0 1 0 1 0 0 1 0]\n [1 1 0 0 1 1 1 1 0 1]]\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639757356330
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('./results/pred_ATnet_many.npy', pred_list_many)\r\n",
        "np.save('./results/label_many.npy', Y_test_many)"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639757535292
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "845270aa2c885a888b45db3c1bae60d031e62d06b801817adb1ea555314d8774"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}